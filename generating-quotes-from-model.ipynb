{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Use a pipeline as a high-level helper\nfrom transformers import pipeline\n\npipe = pipeline(\"text-generation\", model=\"noelmathewisaac/inspirational-quotes-distilgpt2\")","metadata":{"id":"zhJeWIAog12k","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"noelmathewisaac/inspirational-quotes-distilgpt2\")\nmodel = AutoModelForCausalLM.from_pretrained(\"noelmathewisaac/inspirational-quotes-distilgpt2\")","metadata":{"id":"BJys8gusg12o","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"file_path = '/content/drive/My Drive/prepro/generated_quotes.csv'\n\n# Open the file in write mode to clear its content\nwith open(file_path, 'w') as file:\n    file.truncate(0)\n","metadata":{"id":"kyjnrgWWMwTd"}},{"cell_type":"code","source":"import random\nimport torch\nimport pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport os\n\n# Check if a GPU is available and use it\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Load the tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"noelmathewisaac/inspirational-quotes-distilgpt2\")\nmodel = AutoModelForCausalLM.from_pretrained(\"noelmathewisaac/inspirational-quotes-distilgpt2\").to(device)\n\n# Define the path to your dataset in Kaggle\ndataset_path = '/kaggle/input/sssaaammmm/preprocessed_quotes_no_quote_author_category (1).csv'\n\n# Load the preprocessed dataset\npreprocessed_data = pd.read_csv(dataset_path)\n\n# Define the path to save the generated file in Kaggle's working directory\ngenerated_file_path = '/kaggle/working/generated_quotes1.csv'\n\n# Function to generate quotes for each row without overwriting existing quotes\ndef generate_quotes_for_each_row(dataframe, max_rows, generated_file_path, max_length=100, save_every=100):\n    generated_quotes = []\n\n    if os.path.exists(generated_file_path):\n        # Load existing generated quotes and determine the starting index in the dataset\n        existing_quotes_data = pd.read_csv(generated_file_path, delimiter='\\t')\n        num_existing_quotes = len(existing_quotes_data)\n    else:\n        num_existing_quotes = 0\n\n    for index in range(num_existing_quotes, max_rows):\n        entry = dataframe.iloc[index][\"first_3_words\"]\n        seed_text = entry\n        input_ids = tokenizer.encode(seed_text, return_tensors=\"pt\").to(device)\n        attention_mask = torch.ones(input_ids.shape, device=device)\n        output = model.generate(input_ids, max_length=max_length, no_repeat_ngram_size=20, top_k=50, pad_token_id=model.config.eos_token_id, attention_mask=attention_mask)\n        quote = tokenizer.decode(output[0], skip_special_tokens=True)\n\n        generated_quotes.append({\"Generated_Quote\": quote, \"Source_Row\": f\"Row {index + 1}\"})\n\n        if len(generated_quotes) % save_every == 0:\n            # Append newly generated quotes to the existing file every 100 quotes\n            generated_quotes_data = pd.DataFrame(generated_quotes)\n            generated_quotes_data.to_csv(generated_file_path, mode='a', header=False, index=False, sep='\\t')\n            generated_quotes = []  # Clear the list to avoid saving the same quotes multiple times\n            print(f\"Yay {index + 1} saved\")\n\n    # Append any remaining newly generated quotes\n    if generated_quotes:\n        generated_quotes_data = pd.DataFrame(generated_quotes)\n        generated_quotes_data.to_csv(generated_file_path, mode='a', header=False, index=False, sep='\\t')\n        print(f\"Yay {max_rows} saved\")\n\n# Generate up to 1 quote per row for the maximum number of rows\nmax_rows_to_generate = len(preprocessed_data)\ngenerate_quotes_for_each_row(preprocessed_data, max_rows_to_generate, generated_file_path)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kX_J2fKig12p","outputId":"4bc37f11-4860-43bd-e692-d706353bca69","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\n# Source file path\nsource_file = '/kaggle/input/sssaaammmm/generated_quotes.csv'\n\n# Destination file path (working directory)\ndestination_file = '/kaggle/working/generated_quotes1.csv'\n\n# Copy the file to the working directory\nshutil.copy(source_file, destination_file)\n","metadata":{"id":"8KlovSeWkP7e","trusted":true},"execution_count":null,"outputs":[]}]}